# Agentic Loop

A Python agentic loop system supporting both **ReAct** and **Plan-and-Execute** modes, with intelligent memory management and support for multiple LLM providers (Anthropic Claude, OpenAI GPT, Google Gemini).

## Features

- ğŸ¤– **Two Agent Modes**:
  - **ReAct**: Reasoning-Acting loop, ideal for interactive problem-solving
  - **Plan-and-Execute**: Planning-Execution-Synthesis, perfect for complex multi-step tasks

- ğŸ§  **Intelligent Memory Management**:
  - Automatic compression of old messages (30-70% token reduction)
  - LLM-driven summarization for context optimization
  - Token tracking and cost estimation
  - Multiple compression strategies (sliding window, selective, deletion)
  - Supports long-running tasks without context overflow

- ğŸ› ï¸ **Advanced File Tools**:
  - **Glob**: Fast file pattern matching (`**/*.py`, `src/**/*.js`)
  - **Grep**: Regex-based content search with context/count modes
  - **Edit**: Surgical file editing without reading entire contents
  - **Sub-agent Delegation**: Create sub-agents to handle complex subtasks

- ğŸ¤– **Multiple LLM Support**:
  - **Anthropic Claude** (Claude 3.5 Sonnet, Haiku, Opus, etc.)
  - **OpenAI GPT** (GPT-4o, GPT-4o-mini, O1, O3, etc.)
  - **Google Gemini** (Gemini 1.5/2.0 Pro, Flash, etc.)
  - Easy switching between providers via configuration
  - Custom base URL support (proxies, Azure, local deployments)

- ğŸ› ï¸ **Rich Toolset**:
  - File operations (read/write/search/glob/grep/edit)
  - Python code execution and calculator
  - Web search (DuckDuckGo)
  - Shell command execution
  - Sub-agent delegation for complex subtasks

- ğŸ”„ **Robust & Resilient**:
  - Automatic retry with exponential backoff for rate limits (429 errors)
  - Handles API quota exhaustion gracefully
  - Configurable retry behavior per provider

- ğŸ“ **Learning-Friendly**:
  - Clean, modular architecture
  - Comprehensive documentation
  - Easy to extend and customize

## Installation

### Option 1: Install from PyPI (Recommended - Coming Soon)

```bash
pip install agentic-loop
```

### Option 2: Install from Source (Development)

```bash
# Clone the repository
git clone https://github.com/yourusername/AgenticLoop.git
cd AgenticLoop

# Install in development mode
pip install -e .
```

### Option 3: Install from GitHub

```bash
pip install git+https://github.com/yourusername/AgenticLoop.git
```

### Option 4: Docker

```bash
docker pull yourusername/agentic-loop:latest
docker run -it --rm -e ANTHROPIC_API_KEY=your_key agentic-loop interactive
```

## Quick Start

### 1. Configuration

Create `.env` file:

```bash
cp .env.example .env
```

Edit `.env` file and configure your LLM provider:

```bash
# LLM Provider (required)
LLM_PROVIDER=gemini  # Options: anthropic, openai, gemini

# API Keys (set the one for your chosen provider)
ANTHROPIC_API_KEY=your_anthropic_api_key_here
OPENAI_API_KEY=your_openai_api_key_here
GEMINI_API_KEY=your_gemini_api_key_here

# Model (optional - uses provider defaults if not set)
MODEL=gemini-2.5-flash

# Base URLs (optional - for proxies, Azure, local deployments)
ANTHROPIC_BASE_URL=
OPENAI_BASE_URL=
GEMINI_BASE_URL=

# Agent Configuration
MAX_ITERATIONS=100  # Maximum iteration loops

# Memory Management
MEMORY_MAX_CONTEXT_TOKENS=100000
MEMORY_TARGET_TOKENS=30000
MEMORY_COMPRESSION_THRESHOLD=25000
MEMORY_SHORT_TERM_SIZE=100
MEMORY_COMPRESSION_RATIO=0.3

# Retry Configuration (for handling rate limits)
RETRY_MAX_ATTEMPTS=5
RETRY_INITIAL_DELAY=1.0
RETRY_MAX_DELAY=60.0

# Logging
LOG_DIR=logs
LOG_LEVEL=DEBUG
LOG_TO_FILE=true
LOG_TO_CONSOLE=false
```

**Quick setup for different providers:**

- **Anthropic Claude**: Set `LLM_PROVIDER=anthropic` and `ANTHROPIC_API_KEY`
- **OpenAI GPT**: Set `LLM_PROVIDER=openai` and `OPENAI_API_KEY`
- **Google Gemini**: Set `LLM_PROVIDER=gemini` and `GEMINI_API_KEY`

### 2. Usage

#### Command Line (After Installation)

```bash
# Interactive mode
agentic-loop

# Single task (ReAct mode)
agentic-loop --mode react "Calculate 123 * 456"

# Single task (Plan-Execute mode)
agentic-loop --mode plan "Build a web scraper"

# Show help
agentic-loop --help
```

#### Direct Python Execution (Development)

If running from source without installation:

**ReAct Mode (Interactive)**

```bash
python main.py --mode react --task "Calculate 123 * 456"
```

**Plan-and-Execute Mode (Planning)**

```bash
python main.py --mode plan --task "Search for Python agent tutorials and summarize top 3 results"
```

**Interactive Input**

```bash
python main.py --mode react
# Then enter your task, press Enter twice to submit
```

## Memory Management

The system includes intelligent memory management that automatically optimizes token usage for long-running tasks:

```bash
python main.py --task "Complex multi-step task with many iterations..."

# Memory statistics shown at the end:
# --- Memory Statistics ---
# Total tokens: 45,234
# Compressions: 3
# Net savings: 15,678 tokens (34.7%)
# Total cost: $0.0234
```

**Key features:**
- Automatic compression when context grows large
- 30-70% token reduction for long conversations
- Multiple compression strategies
- Cost tracking across providers
- Transparent operation (no code changes needed)

See [Memory Management Documentation](docs/memory-management.md) for detailed information.

## Project Structure

```
agentic-loop/
â”œâ”€â”€ README.md                    # This document
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ .env.example                 # Environment variables template
â”œâ”€â”€ config.py                    # Configuration management
â”œâ”€â”€ main.py                      # CLI entry point
â”œâ”€â”€ docs/                        # ğŸ“š Documentation
â”‚   â”œâ”€â”€ examples.md              # Detailed usage examples
â”‚   â”œâ”€â”€ configuration.md         # Configuration guide
â”‚   â”œâ”€â”€ memory-management.md     # Memory system docs
â”‚   â”œâ”€â”€ advanced-features.md     # Advanced features & optimization
â”‚   â””â”€â”€ extending.md             # Extension guide
â”œâ”€â”€ llm/                         # LLM abstraction layer
â”‚   â”œâ”€â”€ base.py                  # BaseLLM abstract class
â”‚   â”œâ”€â”€ anthropic_llm.py         # Anthropic Claude adapter
â”‚   â”œâ”€â”€ openai_llm.py            # OpenAI GPT adapter
â”‚   â”œâ”€â”€ gemini_llm.py            # Google Gemini adapter
â”‚   â””â”€â”€ retry.py                 # Retry logic for rate limits
â”œâ”€â”€ agent/                       # Agent implementations
â”‚   â”œâ”€â”€ base.py                  # BaseAgent abstract class
â”‚   â”œâ”€â”€ context.py               # Context injection
â”‚   â”œâ”€â”€ react_agent.py           # ReAct mode
â”‚   â”œâ”€â”€ plan_execute_agent.py   # Plan-and-Execute mode
â”‚   â”œâ”€â”€ tool_executor.py         # Tool execution engine
â”‚   â””â”€â”€ todo.py                  # Todo list management
â”œâ”€â”€ memory/                      # ğŸ§  Memory management system
â”‚   â”œâ”€â”€ types.py                 # Core data structures
â”‚   â”œâ”€â”€ manager.py               # Memory orchestrator
â”‚   â”œâ”€â”€ short_term.py            # Short-term memory
â”‚   â”œâ”€â”€ compressor.py            # LLM-driven compression
â”‚   â””â”€â”€ token_tracker.py         # Token tracking & costs
â”œâ”€â”€ tools/                       # Tool implementations
â”‚   â”œâ”€â”€ base.py                  # BaseTool abstract class
â”‚   â”œâ”€â”€ file_ops.py              # File operation tools (read/write/search)
â”‚   â”œâ”€â”€ advanced_file_ops.py     # Advanced tools (Glob/Grep/Edit)
â”‚   â”œâ”€â”€ calculator.py            # Code execution/calculator
â”‚   â”œâ”€â”€ shell.py                 # Shell commands
â”‚   â”œâ”€â”€ web_search.py            # Web search
â”‚   â”œâ”€â”€ todo.py                  # Todo list management
â”‚   â””â”€â”€ delegation.py            # Sub-agent delegation
â”œâ”€â”€ utils/                       # Utilities
â”‚   â””â”€â”€ logger.py                # Logging setup
â””â”€â”€ examples/                    # Example code
    â”œâ”€â”€ react_example.py         # ReAct mode example
    â””â”€â”€ plan_execute_example.py  # Plan-Execute example
```

## Documentation

- **[Examples](docs/examples.md)**: Detailed usage examples and patterns
- **[Configuration](docs/configuration.md)**: Complete configuration guide
- **[Memory Management](docs/memory-management.md)**: Memory system documentation
- **[Advanced Features](docs/advanced-features.md)**: Optimization and advanced techniques
- **[Extending](docs/extending.md)**: How to add tools, agents, and LLM providers
- **[Packaging Guide](docs/packaging.md)**: Package and distribute the system

## Configuration Options

See the full configuration template in `.env.example`. Key options:

| Setting | Description | Default |
|---------|-------------|---------|
| `LLM_PROVIDER` | LLM provider (anthropic/openai/gemini) | `anthropic` |
| `MODEL` | Specific model to use | Provider default |
| `MAX_ITERATIONS` | Maximum agent iterations | `100` |
| `MEMORY_MAX_CONTEXT_TOKENS` | Maximum context window | `100000` |
| `MEMORY_TARGET_TOKENS` | Target working memory size | `30000` |
| `MEMORY_COMPRESSION_THRESHOLD` | Compress when exceeded | `25000` |
| `MEMORY_SHORT_TERM_SIZE` | Recent messages to keep | `100` |
| `RETRY_MAX_ATTEMPTS` | Retry attempts for rate limits | `5` |
| `LOG_LEVEL` | Logging level | `DEBUG` |

See [Configuration Guide](docs/configuration.md) for detailed options.

## Testing

Run basic tests:

```bash
source venv/bin/activate
python test_basic.py
```

## Learning Resources

- **ReAct Paper**: [ReAct: Synergizing Reasoning and Acting in Language Models](https://arxiv.org/abs/2210.03629)
- **Anthropic API Documentation**: [docs.anthropic.com](https://docs.anthropic.com)
- **Tool Use Guide**: [Tool Use (Function Calling)](https://docs.anthropic.com/en/docs/tool-use)

## Future Improvements

- [ ] Streaming output to display agent thinking process
- [x] Intelligent memory management with compression
- [ ] Parallel tool execution
- [ ] Detailed logging and tracing
- [ ] Human-in-the-loop for dangerous operations
- [ ] Multi-agent collaboration system
- [ ] Persistent memory with session recovery
- [ ] Semantic retrieval with vector database

## License

MIT License

## Development

### Building and Packaging

See the [Packaging Guide](docs/packaging.md) for instructions on:
- Building distributable packages
- Publishing to PyPI
- Creating Docker images
- Generating standalone executables

Quick commands:
```bash
# Install locally for development
./scripts/install_local.sh

# Build distribution packages
./scripts/build.sh

# Publish to PyPI
./scripts/publish.sh
```

## Contributing

Contributions are welcome! Please feel free to submit issues and pull requests.

### How to Contribute

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request
